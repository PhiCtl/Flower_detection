{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object_detection_Yolo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1MMLe6oiidsA7QWej2LAFCIuAs4eqMGQ-",
      "authorship_tag": "ABX9TyMJ8SNHts4NXnfqxUTMrOSw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhiCtl/Flower_detection/blob/main/Object_detection_Yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1qcoWdhbnNa"
      },
      "source": [
        "### Acknowledgments \n",
        "* https://github.com/ultralytics/yolov5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb9hbSh8YNbE"
      },
      "source": [
        "# What this notebook allows\n",
        "1. To train the following neural networks :\n",
        "    * Any YOLO network from ultralytics repository\n",
        "2. To visualize their predictions\n",
        "3. To evaluate their performance\n",
        "4. To load a model and make inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA9EeQ4-BlJv"
      },
      "source": [
        "# 1 Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdFgqQtUIkSq"
      },
      "source": [
        "## A) Upload necessary git repositories and packages\n",
        " * My repo\n",
        " * Ultralytics'\n",
        " * Object detection metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEaelsMW-QAh"
      },
      "source": [
        "%%shell\n",
        "# My own repo\n",
        "#rm -r Flower_detection\n",
        "git clone https://github.com/PhiCtl/Flower_detection.git\n",
        "cd Flower_detection/src\n",
        "cp myClasses.py ../../\n",
        "cp myTransforms.py ../../\n",
        "cp myUtils.py ../../\n",
        "cp myTrainingUtils.py ../.."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XZmNeQaPz8L"
      },
      "source": [
        "%%shell\n",
        "git clone https://github.com/ultralytics/yolov5  # master branch (default)\n",
        "cd yolov5\n",
        "pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I018UlGpIH15"
      },
      "source": [
        "%%shell\n",
        "# ref https://github.com/rafaelpadilla/Object-Detection-Metrics#how-to-use-this-project\n",
        "git clone https://github.com/rafaelpadilla/Object-Detection-Metrics.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgTncZVNIsnw"
      },
      "source": [
        "## B) Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcbFooR-a3M0"
      },
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision, cv2, time, copy\n",
        "import torchvision.transforms as T\n",
        "import torch.functional as F\n",
        "from myUtils import*\n",
        "from myTrainingUtils import eval_custom_YOLO\n",
        "from myClasses import FlowerDetectionDataset, Rescale\n",
        "from myTransforms import *\n",
        "from myTrainingUtils import*\n",
        "\n",
        "# ref https://github.com/pytorch/vision/blob/master/references/detection/\n",
        "# ref https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
        "\n",
        "################################################################################\n",
        "# GETTING STARTED\n",
        "################################################################################\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b9S2zTAYTao"
      },
      "source": [
        "## C) Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4SAjj5IcQRB"
      },
      "source": [
        "### Defining Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmui51GWYZBX"
      },
      "source": [
        "myTransform = Rescale((640,640)) # rescale for training\n",
        "transforms_train = T.Compose([T.ToTensor(), T.ColorJitter(0.1, 0.1), T.Normalize(mean=MEAN_Imagenet, std= STD_Imagenet)])\n",
        "transforms_test = get_img_transformed(train=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhfTG7Y6Bz5D"
      },
      "source": [
        "### To rescale the entire dataset and write in YOLO format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsfTS0gcJPxc"
      },
      "source": [
        "def write_lower_res(dataset, train = True, dir = '/content/drive/MyDrive/GBH/rescaled/'):\n",
        "  if train:\n",
        "        path = dir + 'data_train/'\n",
        "  else:\n",
        "        path = dir + 'data_test/'\n",
        "\n",
        "  for (img, target), i in zip(dataset, range(len(dataset))):\n",
        "        img_name, name = path + 'images/' + dataset.imgs[i], dataset.imgs[i][:-4]\n",
        "        ny, nx = img.shape[1:]\n",
        "        file_name = path + 'labels/' + name + '.txt'\n",
        "\n",
        "        cv2.imwrite(img_name, img.numpy().transpose(1,2,0)*255)\n",
        "\n",
        "        f = open(file_name,'w+') # open file in w mode\n",
        "        for label, bbox in zip(target['labels'], target['boxes']):\n",
        "            # compute scaled center box\n",
        "            cx = (bbox[2]+bbox[0])/(2*nx)\n",
        "            cy = (bbox[3]+bbox[1]) / (2*ny)\n",
        "            f.write(\"{} {} {} {} {}\\r\\n\".format(label-1, cx, cy, (bbox[2] -bbox[0])/nx, (bbox[3]-bbox[1])/ny))\n",
        "        f.close()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTNLm1GILitC"
      },
      "source": [
        "write_lower_res(dataset)\n",
        "write_lower_res(dataset_test, train=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKKMxR1UcXu6"
      },
      "source": [
        "### Load train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9-2Ecwdu9M2"
      },
      "source": [
        "################################################################################\n",
        "# LOAD DATASET         \n",
        "################################################################################\n",
        "\n",
        "dataset = FlowerDetectionDataset('/content/drive/MyDrive/GBH/data_train/images/', json_file_root='/content/drive/MyDrive/GBH/labels/export1m.json', custom_transforms=None, transforms=transforms_train)\n",
        "data_loader = DataLoader(\n",
        "    dataset, batch_size=5, shuffle=True, num_workers=2,\n",
        "    collate_fn=collate_fn)\n",
        "\n",
        "dataset_test = FlowerDetectionDataset('/content/drive/MyDrive/GBH/data_test/images/', json_file_root='/content/drive/MyDrive/GBH/labels/export2m.json', custom_transforms=None, transforms=transforms_test)\n",
        "data_loader_test = DataLoader(\n",
        "    dataset_test, batch_size=2, shuffle=False, num_workers=2,\n",
        "    collate_fn=collate_fn)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm1PzayICBwR"
      },
      "source": [
        "### To write into YOLO compatible format\n",
        "Note: Only done once"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPwhrWLIUDMc"
      },
      "source": [
        "import cv2\n",
        "\n",
        "def write_YOLOformat(dataset, dir='/content/drive/MyDrive/GBH/final_test/', root='/content'):\n",
        "    \"\"\"\n",
        "    Write data bouding boxes in format <label><center_x> <center_y> <widht> <height>\n",
        "    and store images in correct dimensions for train\n",
        "    :param dataset:\n",
        "    :param train: (bool) if training set or test set\n",
        "    :param dir: directory containing the folders /data_train an /data_test\n",
        "    :param root: root directory\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    path = dir\n",
        "    # if train:\n",
        "    #     path = dir + 'data_train/'\n",
        "    # else:\n",
        "    #     path = dir + 'data_test/'\n",
        "\n",
        "    # <class_name> <x_center> <y_center> <width> <height>\n",
        "    for (img, target), i in zip(dataset, range(len(dataset))):\n",
        "        name = dataset.imgs[i][:-4]\n",
        "        ny, nx = img.shape[1:]\n",
        "        file_name = path + 'labels/' + name + '.txt'\n",
        "        #img_name = path + 'images_YOLO/' + name + '.jpg'\n",
        "\n",
        "        #cv2.imwrite(img_name, img.numpy().transpose(1,2,0)*255)\n",
        "\n",
        "        f = open(file_name,'w+') # open file in w mode\n",
        "        for label, bbox in zip(target['labels'], target['boxes']):\n",
        "            # compute scaled center box\n",
        "            cx = (bbox[2]+bbox[0])/(2*nx)\n",
        "            cy = (bbox[3]+bbox[1]) / (2*ny)\n",
        "            f.write(\"{} {} {} {} {}\\r\\n\".format(label-1, cx, cy, (bbox[2] -bbox[0])/nx, (bbox[3]-bbox[1])/ny))\n",
        "        f.close()\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlnxVes2yAqO"
      },
      "source": [
        "write_YOLOformat(dataset, train=True)\n",
        "write_YOLOformat(dataset_test, train=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbnBba7GqqDn"
      },
      "source": [
        "To undo, launch batch snippet below.\n",
        "Of course, paths must be changed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHX7LshBC00m"
      },
      "source": [
        "%%bash\n",
        "cd /content/drive/MyDrive/GBH/data_test/\n",
        "rm -r labels\n",
        "cd /content/drive/MyDrive/GBH/data_train/\n",
        "rm -r labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPT4OE6rq6wy"
      },
      "source": [
        "%%bash\n",
        "cd /content/drive/MyDrive/GBH/results/\n",
        "rm -r detections groundtruths\n",
        "mkdir detections\n",
        "mkdir groundtruths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIiq7c9BqZ41"
      },
      "source": [
        "write_YOLOformat(dataset, train=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD2zjzIwqmQI"
      },
      "source": [
        "write_YOLOformat(dataset_test, train=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCPNasHOeDvx"
      },
      "source": [
        "## D) Compute data augmented training set for YOLO training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqh_Db1wd4eV"
      },
      "source": [
        "root_img = '/content/drive/MyDrive/GBH/data_train/images'\n",
        "root_img_tr = '/content/drive/MyDrive/GBH/data_train/images_YOLO'\n",
        "img_list = list(sorted(os.listdir(root_img)))\n",
        "if '.ipynb_checkpoints' in img_list: img_list.remove('.ipynb_checkpoints')\n",
        "\n",
        "transform = T.Compose([T.ToTensor(), \n",
        "                              T.ColorJitter(0.1, 0.1), \n",
        "                              T.Normalize(mean=MEAN_Imagenet, std= STD_Imagenet)])\n",
        "\n",
        "for im_name in img_list:\n",
        "  img = cv2.imread(os.path.join(root_img, im_name))\n",
        "  img_tr = transform(img)\n",
        "  img_tr = img_tr.numpy().transpose(1,2,0) * 255\n",
        "  cv2.imwrite(os.path.join(root_img_tr, im_name), img_tr)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMyIrJcFqPDW"
      },
      "source": [
        "## E) Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4NMDx7fLsuj"
      },
      "source": [
        "### Defining our model\n",
        "We will try YOLO object detector which is mainly used for mobile and real time applications. It comes in different flavours, namely YOLOv3 and YOLOv5 derivatives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1LYX4_flY6K"
      },
      "source": [
        "### Built in training\n",
        "Refer to https://github.com/ultralytics/yolov5 for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxHpSy5lq4u6"
      },
      "source": [
        "%%shell\n",
        "cd yolov5\n",
        "python train.py  --batch 6 --epochs 20 --data /content/drive/MyDrive/GBH/rescaled/train.yaml --weights yolov5x.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkzxhUahCjcB"
      },
      "source": [
        "# 2. Visualize results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDGcVCwVcMQ_"
      },
      "source": [
        "## A) Pick one example on test set\n",
        "Again, look at  https://github.com/ultralytics/yolov5 for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkvTM_45sUYF"
      },
      "source": [
        "%%shell\n",
        "cd yolov5\n",
        "python detect.py --source /content/drive/MyDrive/GBH/data_test/images/20210419_144007.jpg --weights /content/drive/MyDrive/GBH/models/yolo_06062021_1457/best.pt --conf 0.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1K948z4uFSw"
      },
      "source": [
        "## B) Save model\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqgZX_JScI5T"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/yolov5/')\n",
        "from utils.plots import plot_results \n",
        "plot_results(save_dir='runs/train/exp4')  # plot results.txt as results.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj0WlV2lnEVg",
        "outputId": "7e7b32c1-3b6d-4025-c1a8-c5eec4376da0"
      },
      "source": [
        "%%shell\n",
        "mkdir /content/drive/MyDrive/GBH/models/yolo_06062021_1457\n",
        "# mkdir /content/drive/MyDrive/GBH/results/yolov5x\n",
        "mkdir /content/drive/MyDrive/GBH/results/yolov5x/06062021_1457\n",
        "cp /content/yolov5/runs/train/exp4/weights/* /content/drive/MyDrive/GBH/models/yolo_06062021_1457\n",
        "cd /content/yolov5/runs/train/exp4\n",
        "cp F1_curve.png PR_curve.png P_curve.png R_curve.png results.png labels.jpg /content/drive/MyDrive/GBH/results/yolov5x/06062021_1457"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgdjE8mGdu67"
      },
      "source": [
        "# 3. Evaluate model on validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAfPOpJJnj-2"
      },
      "source": [
        "## A) Download model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNNto6s0jW92"
      },
      "source": [
        "import time, torch\n",
        "import torchvision.transforms as T\n",
        "\n",
        "device = torch.device('cpu')\n",
        "weights_path = '/content/drive/MyDrive/GBH/models/yolo_18052021_1550/best.pt' # TODO : change path\n",
        "\n",
        "# Load trained model\n",
        "model_type = 'yolov5x'\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path=weights_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5Tjs200DNFq"
      },
      "source": [
        "## B) Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tXNVpw8xS68"
      },
      "source": [
        "predictions = []\n",
        "path = '/content/drive/MyDrive/GBH/final_test/images/' # path to the validation or test set\n",
        "with torch.no_grad():\n",
        "  for i in range(len(dataset)):\n",
        "    \n",
        "    img_path = path + dataset.imgs[i]\n",
        "    image = cv2.imread(img_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    results = model(image)\n",
        "\n",
        "    target = {}\n",
        "    target['boxes'] = results.xyxy[0][:,:4]\n",
        "    target['scores'] = results.xyxy[0][:,4].flatten()\n",
        "    target['labels'] = results.xyxy[0][:,5].flatten()\n",
        "\n",
        "    predictions.append(target)\n"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op1TXjL-DWAq"
      },
      "source": [
        "Check whether at least one flower has been predicted per frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSJH3YOKKzJc"
      },
      "source": [
        "for i, pred in enumerate(predictions):\n",
        "  if len(pred['boxes']) < 1:\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq1yxj-JDeiS"
      },
      "source": [
        "## C) Write to files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFEeuc-csF_j"
      },
      "source": [
        "def write(dataset, prediction=None, gt=True, initial_dir='/content/drive/MyDrive/GBH/results', root='/content'):\n",
        "    \"\"\"\n",
        "    Writes prediction or groundtruth bboxes to files\n",
        "    :param dataset: (torch.Dataset)\n",
        "    :param prediction: (dic) output of model\n",
        "    :param gt: (bool) if we want to write groundtruth to files\n",
        "    :param initial_dir : should contain the two following subfolders: groundtruths and detections\n",
        "    :param root: root directory\n",
        "   \"\"\"\n",
        "\n",
        "    if gt:\n",
        "        path = initial_dir + '/groundtruths'\n",
        "        os.chdir(path)\n",
        "        # <class_name> <left> <top> <right> <bottom>\n",
        "        for (_, target), i in zip(dataset, range(len(dataset))):\n",
        "            name = dataset.imgs[i]\n",
        "            file_name = name + '.txt'\n",
        "            f = open(file_name, 'w+')  # open file in w mode\n",
        "            for label, bbox in zip(target['labels'], target['boxes']):\n",
        "                f.write(\"{} {} {} {} {}\\r\\n\".format(label, bbox[0], bbox[1], bbox[2], bbox[3]))\n",
        "            f.close()\n",
        "\n",
        "    if prediction is not None:\n",
        "        path = initial_dir + '/detections'\n",
        "        os.chdir(path)\n",
        "        # <class_name> <confidence> <left> <top> <right> <bottom>\n",
        "        for pred, (_, target), i in zip(prediction, dataset, range(len(dataset))):\n",
        "            name = dataset.imgs[i]\n",
        "            file_name = name + '.txt'\n",
        "            f = open(file_name, 'w+')\n",
        "            if len(pred['scores']) >=1 :\n",
        "              for label, score, bbox in zip(pred['labels'], pred['scores'], pred['boxes']):\n",
        "                  f.write(\"{} {} {} {} {} {}\\r\\n\".format(int(label), score, int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])))\n",
        "            else:\n",
        "              f.write(\"1 1 0 0 0 0 \\r\\n\") # arbitrarily false detection\n",
        "            f.close()\n",
        "\n",
        "    os.chdir(root)\n"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc-X408fya7H"
      },
      "source": [
        "write(dataset, predictions, gt=True)"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pa9X1MPDpXF"
      },
      "source": [
        "## D) Evaluate\n",
        "TODO : create a folder to store predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6nkUngHtR0j"
      },
      "source": [
        "%%shell\n",
        "mkdir /content/drive/MyDrive/GBH/results/TEST_FRCNN_mobilenetv3_320/\n",
        "cd Object-Detection-Metrics/\n",
        "python pascalvoc.py  -gt /content/drive/MyDrive/GBH/results/groundtruths/ -det /content/drive/MyDrive/GBH/results/detections/ -gtformat xyrb -detformat xyrb -sp /content/drive/MyDrive/GBH/results/TEST_FRCNN_mobilenetv3_320/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeRVN9dEDu3H"
      },
      "source": [
        "# 4. Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHH6mJlmDzbj"
      },
      "source": [
        "## A) Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1egaRr-IDy1i"
      },
      "source": [
        "import time, torch\n",
        "import torchvision.transforms as T\n",
        "\n",
        "device = torch.device('cpu')\n",
        "weights_path = '/content/drive/MyDrive/GBH/models/yolo_18052021_1550/best.pt' # TODO : change path\n",
        "\n",
        "# Load trained model\n",
        "model_type = 'yolov5x'\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path=weights_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfR6fDYmD1ZA"
      },
      "source": [
        "## B) Load image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-vkl-Lpsav7"
      },
      "source": [
        "import cv2\n",
        "\n",
        "# Load and transform image\n",
        "img = cv2.imread('/content/drive/MyDrive/GBH/final_test/images/pic8_RGB.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img = cv2.resize(img, (640,480))\n"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtfS3AE-D9x8"
      },
      "source": [
        "## C) Compute inference time and make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt0ixb8vovk8"
      },
      "source": [
        "model.conf = 0.25 # set model confidence score if needed\n",
        "tot_time = 0\n",
        "for i in range(3):\n",
        "  t1 = time.time()\n",
        "  results = model(img)\n",
        "  tot_time += (time.time() - t1)\n",
        "print(\"Mean elapsed time : {}s\".format(tot_time/3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eep4wbAPaTYf"
      },
      "source": [
        "results.print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1iItPZ5EFWS"
      },
      "source": [
        "## D) Visualize prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IOLyENrvLTa"
      },
      "source": [
        "target = {}\n",
        "target['boxes'] = results.xyxy[0][:,:4]\n",
        "target['scores'] = results.xyxy[0][:,4].flatten()\n",
        "target['labels'] = results.xyxy[0][:,5].flatten()\n"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7j71h0avdOU"
      },
      "source": [
        "import math\n",
        "def draw_bboxes(image, img_name, target, path ='/content/drive/MyDrive/GBH/final_res/', thresh = 0.3):\n",
        "    img = image.copy()\n",
        "    for [xm,ym,xM,yM], label, score in zip(target[\"boxes\"], target[\"labels\"], target[\"scores\"]):\n",
        "      c = ()\n",
        "      font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "      if int(label) == 0: \n",
        "        c = (255,0,0)\n",
        "        \n",
        "      else: c = (0,255,0)\n",
        "      if score > thresh :\n",
        "        img = cv2.rectangle(img, (xm,ym), (xM,yM), c, 2)\n",
        "        img = cv2.putText(img, str(math.trunc(score.item() * 100)) + '%', (xm,yM), font, 0.5, c, 1, cv2.LINE_AA )\n",
        "    path += img_name\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    cv2.imwrite(path, img)\n",
        "    cv2_imshow(img) ## This line works only for Colab usage"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_811mTCcOCO"
      },
      "source": [
        "draw_bboxes(img_or, 'pic8.jpg', results[0], thresh = 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}