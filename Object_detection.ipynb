{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP4w3z1eyYJxx5hMLFhqcZW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhiCtl/Flower_detection/blob/main/Object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcbFooR-a3M0"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import torchvision.transforms as T\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "# ref https://github.com/pytorch/vision/blob/master/references/detection/\n",
        "# ref https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
        "\n",
        "################################################################################\n",
        "# GETTING STARTED\n",
        "################################################################################\n",
        "\n",
        "MEAN_Imagenet = [0.485, 0.456, 0.406]\n",
        "STD_Imagenet = [0.229, 0.224, 0.225]\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAXx_F1vRoD-"
      },
      "source": [
        "#### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLuU0GgPCE-G"
      },
      "source": [
        "# defined in utils OK\n",
        "def label_reader(json_file):\n",
        "  data = pd.read_json(json_file)\n",
        "  bboxes = {}\n",
        "  for _, d in data.iterrows():\n",
        "    name = d['External ID']\n",
        "    labels = d['Label']['objects']\n",
        "    pix = []\n",
        "    for l in labels:\n",
        "      b = l['bbox']\n",
        "      pix_min = (b['top'],b['left'])\n",
        "      pix_max = (b['top']+b['height'], b['left']+b['width'])\n",
        "      pix.append([pix_min, pix_max])\n",
        "    bboxes[name] = pix\n",
        "  return bboxes"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNmvpPRvLq5V"
      },
      "source": [
        "# defined in utils\n",
        "\n",
        "def get_transformed(train): # TODO: to test\n",
        "  transforms = []\n",
        "  # converts the image into a PyTorch Tensor\n",
        "  transforms.append(T.ToTensor())\n",
        "  # image scaling and normalization\n",
        "  transforms.append(T.Normalize(mean = MEAN_Imagenet, std = STD_Imagenet))\n",
        "  if train:\n",
        "      # during training, randomly flip the training images\n",
        "      # and ground-truth for data augmentation\n",
        "      #TODO: investigate more data augmentation\n",
        "      transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "      transforms.append(T.RandomRotation(degrees=90))\n",
        "  return T.Compose(transforms)\n",
        "  \n",
        "# TODO define metrics to evaluate our model\n",
        "def evaluate_model(model, test):\n",
        "  model.eval()\n",
        "  predictions = model(test['image'],test['target'])\n",
        "\n",
        "# TODO : check if losses are correct, evaluate on training set\n",
        "def train_model(model, train, num_epochs = 100):\n",
        "  \n",
        "  # set model to training mode\n",
        "  model.train()\n",
        "\n",
        "  # construct an optimizer\n",
        "  params = [p for p in model.parameters() if p.requires_grad]\n",
        "  optimizer = torch.optim.Adam(params, lr=0.005,\n",
        "                        momentum=0.9, weight_decay=0.0005)\n",
        "      \n",
        "  # train over epochs\n",
        "  for e in range(num_epochs):\n",
        "\n",
        "    tot_loss = 0\n",
        "    for d in train:\n",
        "      # return losses NOT SURE TODO: check\n",
        "      loss_dict = model(d['image'], d['target'])\n",
        "      losses = sum(loss for loss in loss_dict.values())\n",
        "      tot_loss += losses\n",
        "      # update the learning rate\n",
        "      optimizer.zero_grad()\n",
        "      losses.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    # TODO evaluate here\n",
        "    model.eval()\n",
        "    predictions = model(train['image'],train['target'])\n",
        "    if e % 10 == 0:\n",
        "      print(\"Epochs {}/{}: training liss = {}, \".format(e, num_epochs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkpYbJg7a9mz"
      },
      "source": [
        "## Creating a customed data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcRXkPDya9N7"
      },
      "source": [
        "# defined in classes\n",
        "class FlowerDetectionDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, root, json_file, transforms=None):\n",
        "    self.root = root\n",
        "    self.transforms = transforms\n",
        "    # load all image files, sorting them to\n",
        "    # ensure that they are aligned\n",
        "    self.imgs = list(sorted(os.listdir(os.path.join(root, \"flowers\"))))\n",
        "    self.labels = label_reader(json_file)                                    \n",
        "\n",
        "   def __len__(self):\n",
        "        return len(self.imgs)\n",
        "  \n",
        "   def __getitem__(self, idx):\n",
        "\n",
        "     # load images and bounding boxes\n",
        "     img_path = os.path.join(self.root, \"flowers\", self.imgs[idx])\n",
        "     img = cv2.imread(img_path)\n",
        "     bboxes = self.labels[self.imgs[idx]]\n",
        "\n",
        "     # there is only one class\n",
        "     labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "     \n",
        "     # prepare sample\n",
        "     bboxes = torch.as_tensor(bboxes, dtype=torch.float32)\n",
        "     image_id = torch.tensor([idx])\n",
        "     target = {}\n",
        "     target[\"boxes\"] = bboxes\n",
        "     target[\"labels\"] = labels\n",
        "     target[\"image_id\"] = image_id\n",
        "\n",
        "     if self.transforms is not None:\n",
        "         img = self.transforms(img)\n",
        "\n",
        "     sample[\"image\"], sample[\"target\"] = img, target\n",
        "     return sample\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWk4N3ogRqI-"
      },
      "source": [
        "## Creating a customed model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrjFUgMsP5W_"
      },
      "source": [
        "#define a model class\n",
        "class myModel(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, model_type = 'fasterrcnn_resnet50_fpn', num_classes = 2):\n",
        "    super().__init__()\n",
        "    if model_type == '':\n",
        "      self.model_ = #fill in\n",
        "    else:\n",
        "      self.model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "      in_features = self.model.roi_heads.box_predictor.cls_score.in_features\n",
        "      self.model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.model(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4NMDx7fLsuj"
      },
      "source": [
        "# Defining our model\n",
        "We will be using Faster R-CNN. Faster R-CNN is a model that predicts both bounding boxes and class scores for potential objects in the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgAWfNXKiy3J"
      },
      "source": [
        "\n",
        "################################################################################\n",
        "# LOAD DATASET\n",
        "################################################################################\n",
        "# TODO use our dataset\n",
        "#dataset = \n",
        "#dataset_test = \n",
        "\n",
        "# split the dataset in train and test set\n",
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
        "\n",
        "# define training and validation data loaders\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=2, shuffle=True, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "################################################################################\n",
        "# TRAINING\n",
        "################################################################################\n",
        "# define model\n",
        "# TODO\n",
        "\n",
        "# move model to device\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}